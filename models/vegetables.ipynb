{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fourth-pavilion",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import random\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import imread,subplot,imshow,show\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers, layers, models, callbacks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Conv2D, Flatten, MaxPool2D, Dropout\n",
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-discovery",
   "metadata": {},
   "source": [
    "### Train, validation and test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/grocery_store_dataset'\n",
    "\n",
    "train_dir =  os.path.join(base_dir, 'train/Vegetables')\n",
    "validation_dir =  os.path.join(base_dir, 'val/Vegetables')\n",
    "test_dir =  os.path.join(base_dir, 'test/Vegetables')\n",
    "\n",
    "print('Total number of training vegetable images:', sum(len(files) for _, _, files in os.walk(train_dir)))\n",
    "print('Total number of validation vegetable images:', sum(len(files) for _, _, files in os.walk(validation_dir)))\n",
    "print('Total number of test vegetable images:', sum(len(files) for _, _, files in os.walk(test_dir)))\n",
    "\n",
    "vegetable_classes=[]\n",
    "for root, subdirectories, files in os.walk(train_dir):\n",
    "    for subdirectory in subdirectories:\n",
    "        vegetable_classes.append(subdirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-aaron",
   "metadata": {},
   "source": [
    "### Display dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_images = glob('grocery_store_dataset/train/Vegetables/Carrots/**')\n",
    "random_samples = random.sample(multiple_images, 9)\n",
    "\n",
    "fig, ax = plt.subplots(3, 1,figsize=(20,20))\n",
    "for i in range(3):\n",
    "    ax[i].imshow(imread(random_samples[i])), plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-crowd",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "        rescale=1./255,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_dataset = train_generator.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=25,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_dataset = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1,\n",
    "        shuffle = False,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_dataset = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=10,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-candle",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-experiment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mobilenet_model = mobilenet_v2.MobileNetV2(weights='imagenet',include_top=False, input_shape=(224, 224, 3)) \n",
    "mobilenet_model.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(mobilenet_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(22, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130cbbfb",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience= 3)\n",
    "checkpoint = [\n",
    "            callbacks.ModelCheckpoint(\n",
    "            filepath='./vegetables.h5',\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss')\n",
    "]\n",
    "callbacks=[early_stopping, checkpoint]\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "          batch_size = 36,\n",
    "          epochs=100,\n",
    "          validation_data=validation_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a50b92",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69675329",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Loss')\n",
    "plt.plot(np.arange(0, 1), history.history['loss'], label='train')\n",
    "plt.plot(np.arange(0, 1), history.history['val_loss'], label='val')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(np.arange(0, 1), history.history['accuracy'], label='train')\n",
    "plt.plot(np.arange(0, 1), history.history['val_accuracy'], label='val')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-amino",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vegetables_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-breakdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pred = model.predict(test_dataset)\n",
    "base_pred = base_pred.argmax(axis=1)\n",
    "\n",
    "print(classification_report(test_dataset.classes, base_pred, target_names=vegetable_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
